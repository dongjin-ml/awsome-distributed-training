 5: [compute-gpu-st-distributed-ml-1:77189] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
 3: [compute-gpu-st-distributed-ml-1:77187] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
 2: [compute-gpu-st-distributed-ml-1:77186] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
 4: [compute-gpu-st-distributed-ml-1:77188] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
 7: [compute-gpu-st-distributed-ml-1:77191] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
 6: [compute-gpu-st-distributed-ml-1:77190] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
 0: [compute-gpu-st-distributed-ml-1:77184] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
 1: [compute-gpu-st-distributed-ml-1:77185] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
13: [compute-gpu-st-distributed-ml-2:60029] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
10: [compute-gpu-st-distributed-ml-2:60026] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
11: [compute-gpu-st-distributed-ml-2:60027] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
12: [compute-gpu-st-distributed-ml-2:60028] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
 9: [compute-gpu-st-distributed-ml-2:60025] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
 8: [compute-gpu-st-distributed-ml-2:60024] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
14: [compute-gpu-st-distributed-ml-2:60030] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
15: [compute-gpu-st-distributed-ml-2:60031] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
 2: libfabric:77186:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 2: libfabric:77186:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 0: libfabric:77184:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 0: libfabric:77184:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 6: libfabric:77190:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 6: libfabric:77190:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 5: libfabric:77189:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 5: libfabric:77189:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 7: libfabric:77191:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 7: libfabric:77191:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
10: libfabric:60026:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
10: libfabric:60026:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 4: libfabric:77188:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 4: libfabric:77188:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 3: libfabric:77187:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 3: libfabric:77187:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 9: libfabric:60025:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 9: libfabric:60025:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 1: libfabric:77185:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 1: libfabric:77185:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 8: libfabric:60024:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 8: libfabric:60024:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
13: libfabric:60029:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
13: libfabric:60029:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
11: libfabric:60027:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
11: libfabric:60027:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
15: libfabric:60031:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
15: libfabric:60031:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
12: libfabric:60028:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
12: libfabric:60028:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
14: libfabric:60030:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
14: libfabric:60030:1690073380::core:core:cuda_gdrcopy_hmem_init():191<warn> gdrcopy_dl_hmem_init failed!
 2: libfabric:77186:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::48a:c5ff:fee4:54f]:0:192444428
 2: libfabric:77186:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::48a:c5ff:fee4:54f]:1:1965266728
 0: libfabric:77184:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::48a:c5ff:fee4:54f]:2:1677286491
 6: libfabric:77190:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::48a:c5ff:fee4:54f]:3:1588818681
 0: libfabric:77184:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::48a:c5ff:fee4:54f]:4:1275624362
 6: libfabric:77190:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::48a:c5ff:fee4:54f]:5:1654938850
 5: libfabric:77189:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::492:fff:fe6d:c1ad]:0:1944495195
 7: libfabric:77191:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::492:fff:fe6d:c1ad]:1:989659331
 5: libfabric:77189:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::492:fff:fe6d:c1ad]:2:1030697741
 7: libfabric:77191:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::492:fff:fe6d:c1ad]:3:1707966300
 4: libfabric:77188:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::48a:c5ff:fee4:54f]:6:1141501886
 3: libfabric:77187:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::492:fff:fe6d:c1ad]:4:1219643874
 4: libfabric:77188:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::48a:c5ff:fee4:54f]:7:1844403039
 1: libfabric:77185:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::492:fff:fe6d:c1ad]:5:2090497003
 3: libfabric:77187:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::492:fff:fe6d:c1ad]:6:39541915
10: libfabric:60026:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::4b3:dff:fe02:3769]:0:1971345254
 1: libfabric:77185:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::492:fff:fe6d:c1ad]:7:137812385
10: libfabric:60026:1690073380::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::4b3:dff:fe02:3769]:1:395622004
 9: libfabric:60025:1690073381::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::411:22ff:fe3f:36d]:0:33537385
 9: libfabric:60025:1690073381::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::411:22ff:fe3f:36d]:1:895010614
 8: libfabric:60024:1690073381::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::4b3:dff:fe02:3769]:2:1330924089
13: libfabric:60029:1690073381::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::411:22ff:fe3f:36d]:2:1709363064
 8: libfabric:60024:1690073381::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::4b3:dff:fe02:3769]:3:166062441
11: libfabric:60027:1690073381::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::411:22ff:fe3f:36d]:3:303662218
13: libfabric:60029:1690073381::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::411:22ff:fe3f:36d]:4:1711971983
15: libfabric:60031:1690073381::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::411:22ff:fe3f:36d]:5:1652669638
11: libfabric:60027:1690073381::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::411:22ff:fe3f:36d]:6:1191706139
12: libfabric:60028:1690073381::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::4b3:dff:fe02:3769]:4:141224356
15: libfabric:60031:1690073381::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::411:22ff:fe3f:36d]:7:2039128405
12: libfabric:60028:1690073381::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::4b3:dff:fe02:3769]:5:605179782
14: libfabric:60030:1690073381::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::4b3:dff:fe02:3769]:6:2002642475
14: libfabric:60030:1690073381::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::4b3:dff:fe02:3769]:7:646426315
 0: # nThread 1 nGpus 1 minBytes 8 maxBytes 2147483648 step: 2(factor) warmup iters: 5 iters: 100 agg iters: 1 validation: 1 graph: 0
 0: #
 0: # Using devices
 0: #  Rank  0 Group  0 Pid  77184 on compute-gpu-st-distributed-ml-1 device  0 [0x10] NVIDIA A100-SXM4-40GB
 0: #  Rank  1 Group  0 Pid  77185 on compute-gpu-st-distributed-ml-1 device  1 [0x10] NVIDIA A100-SXM4-40GB
 0: #  Rank  2 Group  0 Pid  77186 on compute-gpu-st-distributed-ml-1 device  2 [0x20] NVIDIA A100-SXM4-40GB
 0: #  Rank  3 Group  0 Pid  77187 on compute-gpu-st-distributed-ml-1 device  3 [0x20] NVIDIA A100-SXM4-40GB
 0: #  Rank  4 Group  0 Pid  77188 on compute-gpu-st-distributed-ml-1 device  4 [0x90] NVIDIA A100-SXM4-40GB
 0: #  Rank  5 Group  0 Pid  77189 on compute-gpu-st-distributed-ml-1 device  5 [0x90] NVIDIA A100-SXM4-40GB
 0: #  Rank  6 Group  0 Pid  77190 on compute-gpu-st-distributed-ml-1 device  6 [0xa0] NVIDIA A100-SXM4-40GB
 0: #  Rank  7 Group  0 Pid  77191 on compute-gpu-st-distributed-ml-1 device  7 [0xa0] NVIDIA A100-SXM4-40GB
 0: #  Rank  8 Group  0 Pid  60024 on compute-gpu-st-distributed-ml-2 device  0 [0x10] NVIDIA A100-SXM4-40GB
 0: #  Rank  9 Group  0 Pid  60025 on compute-gpu-st-distributed-ml-2 device  1 [0x10] NVIDIA A100-SXM4-40GB
 0: #  Rank 10 Group  0 Pid  60026 on compute-gpu-st-distributed-ml-2 device  2 [0x20] NVIDIA A100-SXM4-40GB
 0: #  Rank 11 Group  0 Pid  60027 on compute-gpu-st-distributed-ml-2 device  3 [0x20] NVIDIA A100-SXM4-40GB
 0: #  Rank 12 Group  0 Pid  60028 on compute-gpu-st-distributed-ml-2 device  4 [0x90] NVIDIA A100-SXM4-40GB
 0: #  Rank 13 Group  0 Pid  60029 on compute-gpu-st-distributed-ml-2 device  5 [0x90] NVIDIA A100-SXM4-40GB
 0: #  Rank 14 Group  0 Pid  60030 on compute-gpu-st-distributed-ml-2 device  6 [0xa0] NVIDIA A100-SXM4-40GB
 0: #  Rank 15 Group  0 Pid  60031 on compute-gpu-st-distributed-ml-2 device  7 [0xa0] NVIDIA A100-SXM4-40GB
 0: compute-gpu-st-distributed-ml-1:77184:77184 [0] NCCL INFO Bootstrap : Using eth0:10.1.54.213<0>
 0: compute-gpu-st-distributed-ml-1:77184:77184 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
 0: compute-gpu-st-distributed-ml-1:77184:77184 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
 0: compute-gpu-st-distributed-ml-1:77184:77184 [0] NCCL INFO cudaDriverVersion 12020
 0: NCCL version 2.18.3+cuda12.2
 8: compute-gpu-st-distributed-ml-2:60024:60024 [0] NCCL INFO cudaDriverVersion 12020
 8: compute-gpu-st-distributed-ml-2:60024:60024 [0] NCCL INFO Bootstrap : Using eth0:10.1.62.101<0>
 8: compute-gpu-st-distributed-ml-2:60024:60024 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
 8: compute-gpu-st-distributed-ml-2:60024:60024 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
10: compute-gpu-st-distributed-ml-2:60026:60026 [2] NCCL INFO cudaDriverVersion 12020
10: compute-gpu-st-distributed-ml-2:60026:60026 [2] NCCL INFO Bootstrap : Using eth0:10.1.62.101<0>
10: compute-gpu-st-distributed-ml-2:60026:60026 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
10: compute-gpu-st-distributed-ml-2:60026:60026 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
11: compute-gpu-st-distributed-ml-2:60027:60027 [3] NCCL INFO cudaDriverVersion 12020
11: compute-gpu-st-distributed-ml-2:60027:60027 [3] NCCL INFO Bootstrap : Using eth0:10.1.62.101<0>
11: compute-gpu-st-distributed-ml-2:60027:60027 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
11: compute-gpu-st-distributed-ml-2:60027:60027 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
 9: compute-gpu-st-distributed-ml-2:60025:60025 [1] NCCL INFO cudaDriverVersion 12020
14: compute-gpu-st-distributed-ml-2:60030:60030 [6] NCCL INFO cudaDriverVersion 12020
15: compute-gpu-st-distributed-ml-2:60031:60031 [7] NCCL INFO cudaDriverVersion 12020
13: compute-gpu-st-distributed-ml-2:60029:60029 [5] NCCL INFO cudaDriverVersion 12020
12: compute-gpu-st-distributed-ml-2:60028:60028 [4] NCCL INFO cudaDriverVersion 12020
 9: compute-gpu-st-distributed-ml-2:60025:60025 [1] NCCL INFO Bootstrap : Using eth0:10.1.62.101<0>
14: compute-gpu-st-distributed-ml-2:60030:60030 [6] NCCL INFO Bootstrap : Using eth0:10.1.62.101<0>
14: compute-gpu-st-distributed-ml-2:60030:60030 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
14: compute-gpu-st-distributed-ml-2:60030:60030 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
 9: compute-gpu-st-distributed-ml-2:60025:60025 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
 9: compute-gpu-st-distributed-ml-2:60025:60025 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
15: compute-gpu-st-distributed-ml-2:60031:60031 [7] NCCL INFO Bootstrap : Using eth0:10.1.62.101<0>
12: compute-gpu-st-distributed-ml-2:60028:60028 [4] NCCL INFO Bootstrap : Using eth0:10.1.62.101<0>
13: compute-gpu-st-distributed-ml-2:60029:60029 [5] NCCL INFO Bootstrap : Using eth0:10.1.62.101<0>
15: compute-gpu-st-distributed-ml-2:60031:60031 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
15: compute-gpu-st-distributed-ml-2:60031:60031 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
12: compute-gpu-st-distributed-ml-2:60028:60028 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
13: compute-gpu-st-distributed-ml-2:60029:60029 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
13: compute-gpu-st-distributed-ml-2:60029:60029 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
12: compute-gpu-st-distributed-ml-2:60028:60028 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
 5: compute-gpu-st-distributed-ml-1:77189:77189 [5] NCCL INFO cudaDriverVersion 12020
 5: compute-gpu-st-distributed-ml-1:77189:77189 [5] NCCL INFO Bootstrap : Using eth0:10.1.54.213<0>
 5: compute-gpu-st-distributed-ml-1:77189:77189 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
 5: compute-gpu-st-distributed-ml-1:77189:77189 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
 6: compute-gpu-st-distributed-ml-1:77190:77190 [6] NCCL INFO cudaDriverVersion 12020
 6: compute-gpu-st-distributed-ml-1:77190:77190 [6] NCCL INFO Bootstrap : Using eth0:10.1.54.213<0>
 6: compute-gpu-st-distributed-ml-1:77190:77190 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
 6: compute-gpu-st-distributed-ml-1:77190:77190 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
 7: compute-gpu-st-distributed-ml-1:77191:77191 [7] NCCL INFO cudaDriverVersion 12020
 7: compute-gpu-st-distributed-ml-1:77191:77191 [7] NCCL INFO Bootstrap : Using eth0:10.1.54.213<0>
 7: compute-gpu-st-distributed-ml-1:77191:77191 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
 7: compute-gpu-st-distributed-ml-1:77191:77191 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
 4: compute-gpu-st-distributed-ml-1:77188:77188 [4] NCCL INFO cudaDriverVersion 12020
 4: compute-gpu-st-distributed-ml-1:77188:77188 [4] NCCL INFO Bootstrap : Using eth0:10.1.54.213<0>
 4: compute-gpu-st-distributed-ml-1:77188:77188 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
 4: compute-gpu-st-distributed-ml-1:77188:77188 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
 2: compute-gpu-st-distributed-ml-1:77186:77186 [2] NCCL INFO cudaDriverVersion 12020
 2: compute-gpu-st-distributed-ml-1:77186:77186 [2] NCCL INFO Bootstrap : Using eth0:10.1.54.213<0>
 2: compute-gpu-st-distributed-ml-1:77186:77186 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
 2: compute-gpu-st-distributed-ml-1:77186:77186 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
 3: compute-gpu-st-distributed-ml-1:77187:77187 [3] NCCL INFO cudaDriverVersion 12020
 1: compute-gpu-st-distributed-ml-1:77185:77185 [1] NCCL INFO cudaDriverVersion 12020
 3: compute-gpu-st-distributed-ml-1:77187:77187 [3] NCCL INFO Bootstrap : Using eth0:10.1.54.213<0>
 3: compute-gpu-st-distributed-ml-1:77187:77187 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
 3: compute-gpu-st-distributed-ml-1:77187:77187 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
 1: compute-gpu-st-distributed-ml-1:77185:77185 [1] NCCL INFO Bootstrap : Using eth0:10.1.54.213<0>
 1: compute-gpu-st-distributed-ml-1:77185:77185 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
 1: compute-gpu-st-distributed-ml-1:77185:77185 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO NET/OFI Configuring AWS-specific options
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO NET/OFI Setting NCCL_PROTO to "simple"
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Using network AWS Libfabric
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO NET/OFI Configuring AWS-specific options
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO NET/OFI Setting NCCL_PROTO to "simple"
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Using network AWS Libfabric
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO NET/OFI Configuring AWS-specific options
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO NET/OFI Setting NCCL_PROTO to "simple"
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Using network AWS Libfabric
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO NET/OFI Configuring AWS-specific options
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO NET/OFI Setting NCCL_PROTO to "simple"
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Using network AWS Libfabric
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO NET/OFI Configuring AWS-specific options
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO NET/OFI Setting NCCL_PROTO to "simple"
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Using network AWS Libfabric
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO NET/OFI Configuring AWS-specific options
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO NET/OFI Setting NCCL_PROTO to "simple"
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Using network AWS Libfabric
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO NET/OFI Configuring AWS-specific options
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO NET/OFI Setting NCCL_PROTO to "simple"
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Using network AWS Libfabric
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO NET/OFI Configuring AWS-specific options
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO NET/OFI Setting NCCL_PROTO to "simple"
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Using network AWS Libfabric
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO NET/OFI Configuring AWS-specific options
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO NET/OFI Setting NCCL_PROTO to "simple"
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Using network AWS Libfabric
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO NET/OFI Configuring AWS-specific options
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO NET/OFI Setting NCCL_PROTO to "simple"
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Using network AWS Libfabric
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO NET/OFI Configuring AWS-specific options
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO NET/OFI Setting NCCL_PROTO to "simple"
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Using network AWS Libfabric
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO NET/OFI Configuring AWS-specific options
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO NET/OFI Setting NCCL_PROTO to "simple"
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Using network AWS Libfabric
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO NET/OFI Configuring AWS-specific options
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO NET/OFI Setting NCCL_PROTO to "simple"
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Using network AWS Libfabric
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO NET/OFI Configuring AWS-specific options
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO NET/OFI Setting NCCL_PROTO to "simple"
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Using network AWS Libfabric
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO NET/OFI Configuring AWS-specific options
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO NET/OFI Setting NCCL_PROTO to "simple"
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Using network AWS Libfabric
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO NET/OFI Using aws-ofi-nccl 1.5.0aws
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO NET/OFI Configuring AWS-specific options
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO NET/OFI Setting NCCL_PROTO to "simple"
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Using network AWS Libfabric
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO comm 0x5637ea53e2f0 rank 14 nranks 16 cudaDev 6 nvmlDev 6 busId a01c0 commId 0x94343f5a50e0fc8e - Init START
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO comm 0x5559cbb825c0 rank 0 nranks 16 cudaDev 0 nvmlDev 0 busId 101c0 commId 0x94343f5a50e0fc8e - Init START
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO comm 0x564af14721d0 rank 15 nranks 16 cudaDev 7 nvmlDev 7 busId a01d0 commId 0x94343f5a50e0fc8e - Init START
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO comm 0x5605a8b16440 rank 12 nranks 16 cudaDev 4 nvmlDev 4 busId 901c0 commId 0x94343f5a50e0fc8e - Init START
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO comm 0x560bd1fa4640 rank 1 nranks 16 cudaDev 1 nvmlDev 1 busId 101d0 commId 0x94343f5a50e0fc8e - Init START
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO comm 0x55b255c27e20 rank 13 nranks 16 cudaDev 5 nvmlDev 5 busId 901d0 commId 0x94343f5a50e0fc8e - Init START
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO comm 0x5613e001b5c0 rank 2 nranks 16 cudaDev 2 nvmlDev 2 busId 201c0 commId 0x94343f5a50e0fc8e - Init START
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO comm 0x5650a588b3d0 rank 10 nranks 16 cudaDev 2 nvmlDev 2 busId 201c0 commId 0x94343f5a50e0fc8e - Init START
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO comm 0x562ff6427610 rank 3 nranks 16 cudaDev 3 nvmlDev 3 busId 201d0 commId 0x94343f5a50e0fc8e - Init START
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO comm 0x55670668f200 rank 11 nranks 16 cudaDev 3 nvmlDev 3 busId 201d0 commId 0x94343f5a50e0fc8e - Init START
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO comm 0x5626f5bda160 rank 4 nranks 16 cudaDev 4 nvmlDev 4 busId 901c0 commId 0x94343f5a50e0fc8e - Init START
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO comm 0x55a489a7b1a0 rank 8 nranks 16 cudaDev 0 nvmlDev 0 busId 101c0 commId 0x94343f5a50e0fc8e - Init START
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO comm 0x55ff5096fdf0 rank 5 nranks 16 cudaDev 5 nvmlDev 5 busId 901d0 commId 0x94343f5a50e0fc8e - Init START
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO comm 0x5599acfaccd0 rank 9 nranks 16 cudaDev 1 nvmlDev 1 busId 101d0 commId 0x94343f5a50e0fc8e - Init START
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO comm 0x558fa21e42d0 rank 6 nranks 16 cudaDev 6 nvmlDev 6 busId a01c0 commId 0x94343f5a50e0fc8e - Init START
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO comm 0x55775a100140 rank 7 nranks 16 cudaDev 7 nvmlDev 7 busId a01d0 commId 0x94343f5a50e0fc8e - Init START
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/aws-ofi-nccl/install/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO NVLS multicast support is not available on dev 7
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO NVLS multicast support is not available on dev 4
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO NVLS multicast support is not available on dev 6
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Setting affinity for GPU 2 to 02
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO NVLS multicast support is not available on dev 2
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Setting affinity for GPU 3 to 020000,00000000
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO NVLS multicast support is not available on dev 3
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO NVLS multicast support is not available on dev 5
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Setting affinity for GPU 0 to 01
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO NVLS multicast support is not available on dev 0
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Setting affinity for GPU 1 to 010000,00000000
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO NVLS multicast support is not available on dev 1
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Setting affinity for GPU 3 to 020000,00000000
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO NVLS multicast support is not available on dev 3
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO NVLS multicast support is not available on dev 5
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO NVLS multicast support is not available on dev 7
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO NVLS multicast support is not available on dev 4
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Setting affinity for GPU 2 to 02
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO NVLS multicast support is not available on dev 2
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO NVLS multicast support is not available on dev 6
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Setting affinity for GPU 0 to 01
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO NVLS multicast support is not available on dev 0
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Setting affinity for GPU 1 to 010000,00000000
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO NVLS multicast support is not available on dev 1
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/14/-1->6->-1 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->14
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO P2P Chunksize set to 131072
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] 0/-1/-1->7->6 [2] 0/-1/-1->7->6 [3] 0/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] 0/-1/-1->7->6 [6] 0/-1/-1->7->6 [7] 0/-1/-1->7->6
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO P2P Chunksize set to 131072
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/12/-1->4->-1 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->12 [7] 5/-1/-1->4->3
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO P2P Chunksize set to 131072
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->2 [2] 11/-1/-1->10->9 [3] 11/-1/-1->10->9 [4] 11/-1/-1->10->9 [5] 11/2/-1->10->-1 [6] 11/-1/-1->10->9 [7] 11/-1/-1->10->9
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO P2P Chunksize set to 131072
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] -1/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] -1/-1/-1->5->4
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO P2P Chunksize set to 131072
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 00/08 :    0   7   6   5   4   3   2   1   8  15  14  13  12  11  10   9
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/10/-1->2->-1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->10 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO P2P Chunksize set to 131072
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] -1/-1/-1->3->2 [7] 4/-1/-1->3->2
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO P2P Chunksize set to 131072
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 01/08 :    0   3  10  15  14  13  12   9   8  11   2   7   6   5   4   1
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 02/08 :    0   7   6   5  12  11  10   9   8  15  14  13   4   3   2   1
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 03/08 :    0   5   4   7  14  11  10   9   8  13  12  15   6   3   2   1
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 04/08 :    0   7   6   5   4   3   2   1   8  15  14  13  12  11  10   9
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 05/08 :    0   3  10  15  14  13  12   9   8  11   2   7   6   5   4   1
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 06/08 :    0   7   6   5  12  11  10   9   8  15  14  13   4   3   2   1
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 07/08 :    0   5   4   7  14  11  10   9   8  13  12  15   6   3   2   1
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO P2P Chunksize set to 131072
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Trees [0] 1/8/-1->0->-1 [1] 1/-1/-1->0->7 [2] 1/-1/-1->0->7 [3] 1/-1/-1->0->7 [4] 1/-1/-1->0->8 [5] 1/-1/-1->0->7 [6] 1/-1/-1->0->7 [7] 1/-1/-1->0->7
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO P2P Chunksize set to 131072
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Trees [0] 12/-1/-1->11->10 [1] 12/-1/-1->11->10 [2] -1/-1/-1->11->10 [3] 12/-1/-1->11->10 [4] 12/-1/-1->11->10 [5] 12/-1/-1->11->10 [6] -1/-1/-1->11->10 [7] 12/-1/-1->11->10
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO P2P Chunksize set to 131072
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Trees [0] 13/-1/-1->12->11 [1] 13/-1/-1->12->11 [2] 13/-1/-1->12->4 [3] 13/-1/-1->12->11 [4] 13/-1/-1->12->11 [5] 13/-1/-1->12->11 [6] 13/4/-1->12->-1 [7] 13/-1/-1->12->11
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO P2P Chunksize set to 131072
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/-1/-1->13->12 [2] 14/-1/-1->13->12 [3] -1/-1/-1->13->12 [4] 14/-1/-1->13->12 [5] 14/-1/-1->13->12 [6] 14/-1/-1->13->12 [7] -1/-1/-1->13->12
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO P2P Chunksize set to 131072
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13 [2] 15/-1/-1->14->13 [3] 15/-1/-1->14->6 [4] 15/-1/-1->14->13 [5] 15/-1/-1->14->13 [6] 15/-1/-1->14->13 [7] 15/6/-1->14->-1
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO P2P Chunksize set to 131072
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] 8/-1/-1->15->14 [2] 8/-1/-1->15->14 [3] 8/-1/-1->15->14 [4] -1/-1/-1->15->14 [5] 8/-1/-1->15->14 [6] 8/-1/-1->15->14 [7] 8/-1/-1->15->14
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO P2P Chunksize set to 131072
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Trees [0] 10/-1/-1->9->8 [1] -1/-1/-1->9->8 [2] 10/-1/-1->9->8 [3] 10/-1/-1->9->8 [4] 10/-1/-1->9->8 [5] -1/-1/-1->9->8 [6] 10/-1/-1->9->8 [7] 10/-1/-1->9->8
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO P2P Chunksize set to 131072
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Trees [0] 9/-1/-1->8->0 [1] 9/-1/-1->8->15 [2] 9/-1/-1->8->15 [3] 9/-1/-1->8->15 [4] 9/0/-1->8->-1 [5] 9/-1/-1->8->15 [6] 9/-1/-1->8->15 [7] 9/-1/-1->8->15
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO P2P Chunksize set to 131072
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 03/0 : 12[4] -> 15[7] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 03/0 : 4[4] -> 7[7] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 01/0 : 10[2] -> 15[7] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 01/0 : 2[2] -> 7[7] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 01/0 : 0[0] -> 3[3] via P2P/IPC/read
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 01/0 : 8[0] -> 11[3] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 05/0 : 10[2] -> 15[7] via P2P/IPC/read
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 05/0 : 8[0] -> 11[3] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 07/0 : 12[4] -> 15[7] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 05/0 : 2[2] -> 7[7] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 07/0 : 4[4] -> 7[7] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/IPC/read
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 03/0 : 8[0] -> 13[5] via P2P/IPC/read
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Channel 00/0 : 9[1] -> 0[0] [send] via NET/AWS Libfabric/0/GDRDMA
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Channel 04/0 : 9[1] -> 0[0] [send] via NET/AWS Libfabric/0/GDRDMA
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 03/0 : 0[0] -> 5[5] via P2P/IPC/read
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Channel 00/0 : 1[1] -> 8[0] [send] via NET/AWS Libfabric/0/GDRDMA
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Channel 04/0 : 1[1] -> 8[0] [send] via NET/AWS Libfabric/0/GDRDMA
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 07/0 : 8[0] -> 13[5] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 07/0 : 0[0] -> 5[5] via P2P/IPC/read
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Channel 01/0 : 3[3] -> 10[2] [send] via NET/AWS Libfabric/1/GDRDMA
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Channel 05/0 : 3[3] -> 10[2] [send] via NET/AWS Libfabric/1/GDRDMA
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Channel 01/0 : 11[3] -> 2[2] [send] via NET/AWS Libfabric/1/GDRDMA
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Channel 05/0 : 11[3] -> 2[2] [send] via NET/AWS Libfabric/1/GDRDMA
14: libfabric:60030:1690073387::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::405:b1ff:fe9e:bdab]:0:1926341948
 6: libfabric:77190:1690073387::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::491:96ff:fe3e:4035]:0:32820410
12: libfabric:60028:1690073387::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::456:a9ff:fed7:cff1]:0:364197523
 4: libfabric:77188:1690073387::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::4b3:d2ff:fedf:3ed7]:0:203418200
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Channel 03/0 : 15[7] -> 6[6] [send] via NET/AWS Libfabric/3/GDRDMA
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Channel 07/0 : 15[7] -> 6[6] [send] via NET/AWS Libfabric/3/GDRDMA
10: libfabric:60026:1690073387::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::411:22ff:fe3f:36d]:8:491807477
 8: libfabric:60024:1690073387::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::4b3:dff:fe02:3769]:8:467694009
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Channel 03/0 : 7[7] -> 14[6] [send] via NET/AWS Libfabric/3/GDRDMA
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Channel 07/0 : 7[7] -> 14[6] [send] via NET/AWS Libfabric/3/GDRDMA
 0: libfabric:77184:1690073387::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::48a:c5ff:fee4:54f]:8:1214924925
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Channel 02/0 : 13[5] -> 4[4] [send] via NET/AWS Libfabric/2/GDRDMA
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Channel 06/0 : 13[5] -> 4[4] [send] via NET/AWS Libfabric/2/GDRDMA
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Channel 02/0 : 5[5] -> 12[4] [send] via NET/AWS Libfabric/2/GDRDMA
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Channel 06/0 : 5[5] -> 12[4] [send] via NET/AWS Libfabric/2/GDRDMA
 2: libfabric:77186:1690073387::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::492:fff:fe6d:c1ad]:8:1347634285
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 03/0 : 7[7] -> 14[6] [receive] via NET/AWS Libfabric/3/GDRDMA
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 07/0 : 7[7] -> 14[6] [receive] via NET/AWS Libfabric/3/GDRDMA
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 03/0 : 14[6] -> 11[3] via P2P/IPC/read
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 07/0 : 14[6] -> 11[3] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 02/0 : 5[5] -> 12[4] [receive] via NET/AWS Libfabric/2/GDRDMA
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 06/0 : 5[5] -> 12[4] [receive] via NET/AWS Libfabric/2/GDRDMA
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 01/0 : 12[4] -> 9[1] via P2P/IPC/read
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 03/0 : 15[7] -> 6[6] [receive] via NET/AWS Libfabric/3/GDRDMA
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 07/0 : 15[7] -> 6[6] [receive] via NET/AWS Libfabric/3/GDRDMA
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 03/0 : 6[6] -> 3[3] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 05/0 : 12[4] -> 9[1] via P2P/IPC/read
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 07/0 : 6[6] -> 3[3] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 02/0 : 13[5] -> 4[4] [receive] via NET/AWS Libfabric/2/GDRDMA
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 06/0 : 13[5] -> 4[4] [receive] via NET/AWS Libfabric/2/GDRDMA
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 01/0 : 4[4] -> 1[1] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 05/0 : 4[4] -> 1[1] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 01/0 : 3[3] -> 10[2] [receive] via NET/AWS Libfabric/1/GDRDMA
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 05/0 : 3[3] -> 10[2] [receive] via NET/AWS Libfabric/1/GDRDMA
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 00/0 : 1[1] -> 8[0] [receive] via NET/AWS Libfabric/0/GDRDMA
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 04/0 : 1[1] -> 8[0] [receive] via NET/AWS Libfabric/0/GDRDMA
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 00/0 : 8[0] -> 15[7] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 00/0 : 9[1] -> 0[0] [receive] via NET/AWS Libfabric/0/GDRDMA
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 04/0 : 9[1] -> 0[0] [receive] via NET/AWS Libfabric/0/GDRDMA
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 00/0 : 0[0] -> 7[7] via P2P/IPC/read
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 02/0 : 8[0] -> 15[7] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 02/0 : 0[0] -> 7[7] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 04/0 : 0[0] -> 7[7] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 06/0 : 0[0] -> 7[7] via P2P/IPC/read
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 04/0 : 8[0] -> 15[7] via P2P/IPC/read
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 06/0 : 8[0] -> 15[7] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 00/0 : 10[2] -> 9[1] via P2P/IPC/read
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Channel 00/0 : 7[7] -> 6[6] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 02/0 : 10[2] -> 9[1] via P2P/IPC/read
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Channel 00/0 : 15[7] -> 14[6] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 03/0 : 10[2] -> 9[1] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 04/0 : 10[2] -> 9[1] via P2P/IPC/read
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 06/0 : 10[2] -> 9[1] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 07/0 : 10[2] -> 9[1] via P2P/IPC/read
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/IPC/read
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Channel 00/0 : 13[5] -> 12[4] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 01/0 : 11[3] -> 2[2] [receive] via NET/AWS Libfabric/1/GDRDMA
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 05/0 : 11[3] -> 2[2] [receive] via NET/AWS Libfabric/1/GDRDMA
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Channel 01/0 : 7[7] -> 6[6] via P2P/IPC/read
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Channel 01/0 : 13[5] -> 12[4] via P2P/IPC/read
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Channel 01/0 : 15[7] -> 14[6] via P2P/IPC/read
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Channel 02/0 : 7[7] -> 6[6] via P2P/IPC/read
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Channel 03/0 : 5[5] -> 4[4] via P2P/IPC/read
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Channel 03/0 : 13[5] -> 12[4] via P2P/IPC/read
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Channel 04/0 : 5[5] -> 4[4] via P2P/IPC/read
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Channel 04/0 : 13[5] -> 12[4] via P2P/IPC/read
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Channel 02/0 : 15[7] -> 14[6] via P2P/IPC/read
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Channel 04/0 : 15[7] -> 14[6] via P2P/IPC/read
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Channel 04/0 : 7[7] -> 6[6] via P2P/IPC/read
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Channel 05/0 : 13[5] -> 12[4] via P2P/IPC/read
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Channel 05/0 : 5[5] -> 4[4] via P2P/IPC/read
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Channel 05/0 : 15[7] -> 14[6] via P2P/IPC/read
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Channel 07/0 : 13[5] -> 12[4] via P2P/IPC/read
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Channel 06/0 : 15[7] -> 14[6] via P2P/IPC/read
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Channel 07/0 : 5[5] -> 4[4] via P2P/IPC/read
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/IPC/read
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Channel 05/0 : 7[7] -> 6[6] via P2P/IPC/read
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/IPC/read
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Channel 01/0 : 9[1] -> 8[0] via P2P/IPC/read
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Channel 02/0 : 9[1] -> 8[0] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/IPC/read
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Channel 06/0 : 7[7] -> 6[6] via P2P/IPC/read
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Channel 03/0 : 9[1] -> 8[0] via P2P/IPC/read
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/IPC/read
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Channel 05/0 : 9[1] -> 8[0] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 02/0 : 2[2] -> 1[1] via P2P/IPC/read
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Channel 06/0 : 9[1] -> 8[0] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/IPC/read
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/IPC/read
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Channel 04/0 : 3[3] -> 2[2] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/IPC/read
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Channel 07/0 : 9[1] -> 8[0] via P2P/IPC/read
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 06/0 : 2[2] -> 1[1] via P2P/IPC/read
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Channel 06/0 : 3[3] -> 2[2] via P2P/IPC/read
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 00/0 : 6[6] -> 5[5] via P2P/IPC/read
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Channel 00/0 : 11[3] -> 10[2] via P2P/IPC/read
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 07/0 : 2[2] -> 1[1] via P2P/IPC/read
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/IPC/read
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 01/0 : 6[6] -> 5[5] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 00/0 : 12[4] -> 11[3] via P2P/IPC/read
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 02/0 : 6[6] -> 5[5] via P2P/IPC/read
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/IPC/read
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Channel 02/0 : 11[3] -> 10[2] via P2P/IPC/read
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/IPC/read
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 04/0 : 6[6] -> 5[5] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 02/0 : 12[4] -> 11[3] via P2P/IPC/read
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 05/0 : 6[6] -> 5[5] via P2P/IPC/read
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/IPC/read
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 06/0 : 6[6] -> 5[5] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/IPC/read
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Channel 03/0 : 11[3] -> 10[2] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 04/0 : 12[4] -> 11[3] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 06/0 : 12[4] -> 11[3] via P2P/IPC/read
 9: libfabric:60025:1690073387::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::4b3:dff:fe02:3769]:9:171977065
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 02/0 : 4[4] -> 3[3] via P2P/IPC/read
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Channel 04/0 : 11[3] -> 10[2] via P2P/IPC/read
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Channel 06/0 : 11[3] -> 10[2] via P2P/IPC/read
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Channel 07/0 : 11[3] -> 10[2] via P2P/IPC/read
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 00/0 : 14[6] -> 13[5] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 04/0 : 4[4] -> 3[3] via P2P/IPC/read
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 01/0 : 14[6] -> 13[5] via P2P/IPC/read
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 02/0 : 14[6] -> 13[5] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 06/0 : 4[4] -> 3[3] via P2P/IPC/read
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 04/0 : 14[6] -> 13[5] via P2P/IPC/read
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 05/0 : 14[6] -> 13[5] via P2P/IPC/read
11: libfabric:60027:1690073387::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::411:22ff:fe3f:36d]:9:813880339
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 06/0 : 14[6] -> 13[5] via P2P/IPC/read
 1: libfabric:77185:1690073387::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::48a:c5ff:fee4:54f]:9:323036663
 7: libfabric:77191:1690073387::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::491:96ff:fe3e:4035]:1:1908569274
 5: libfabric:77189:1690073387::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::4b3:d2ff:fedf:3ed7]:1:1662561741
 3: libfabric:77187:1690073387::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::492:fff:fe6d:c1ad]:9:1602409344
13: libfabric:60029:1690073387::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::456:a9ff:fed7:cff1]:1:1831168727
15: libfabric:60031:1690073387::efa:ep_ctrl:rxr_ep_ctrl():939<warn> libfabric 1.18.1 efa endpoint created! address: fi_addr_efa://[fe80::405:b1ff:fe9e:bdab]:1:1359672522
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Connected all rings
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Channel 00/0 : 9[1] -> 10[2] via P2P/IPC/read
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Channel 02/0 : 9[1] -> 10[2] via P2P/IPC/read
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Channel 03/0 : 9[1] -> 10[2] via P2P/IPC/read
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Channel 04/0 : 9[1] -> 10[2] via P2P/IPC/read
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Channel 06/0 : 9[1] -> 10[2] via P2P/IPC/read
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Channel 07/0 : 9[1] -> 10[2] via P2P/IPC/read
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Connected all rings
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Connected all rings
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Connected all rings
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 00/0 : 8[0] -> 9[1] via P2P/IPC/read
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Connected all rings
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 01/0 : 8[0] -> 9[1] via P2P/IPC/read
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 02/0 : 8[0] -> 9[1] via P2P/IPC/read
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 03/0 : 8[0] -> 9[1] via P2P/IPC/read
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 04/0 : 8[0] -> 9[1] via P2P/IPC/read
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Connected all rings
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 05/0 : 8[0] -> 9[1] via P2P/IPC/read
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Connected all rings
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 06/0 : 8[0] -> 9[1] via P2P/IPC/read
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Channel 00/0 : 11[3] -> 12[4] via P2P/IPC/read
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 07/0 : 8[0] -> 9[1] via P2P/IPC/read
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Channel 01/0 : 11[3] -> 12[4] via P2P/IPC/read
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Channel 03/0 : 11[3] -> 12[4] via P2P/IPC/read
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 01/0 : 8[0] -> 15[7] via P2P/IPC/read
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 03/0 : 8[0] -> 15[7] via P2P/IPC/read
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 05/0 : 8[0] -> 15[7] via P2P/IPC/read
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Channel 04/0 : 11[3] -> 12[4] via P2P/IPC/read
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Channel 05/0 : 11[3] -> 12[4] via P2P/IPC/read
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 07/0 : 8[0] -> 15[7] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Connected all rings
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC/read
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 00/0 : 14[6] -> 15[7] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/IPC/read
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Channel 07/0 : 11[3] -> 12[4] via P2P/IPC/read
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Connected all rings
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 01/0 : 14[6] -> 15[7] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC/read
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 02/0 : 14[6] -> 15[7] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Connected all rings
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Connected all rings
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Connected all rings
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/IPC/read
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Connected all rings
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/IPC/read
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 03/0 : 14[6] -> 15[7] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Connected all rings
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Channel 02/0 : 1[1] -> 2[2] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/IPC/read
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Connected all rings
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/IPC/read
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 04/0 : 14[6] -> 15[7] via P2P/IPC/read
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/IPC/read
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 05/0 : 14[6] -> 15[7] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 03/0 : 2[2] -> 3[3] via P2P/IPC/read
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Connected all rings
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/IPC/read
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 06/0 : 14[6] -> 15[7] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/IPC/read
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/IPC/read
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 07/0 : 14[6] -> 15[7] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 00/0 : 10[2] -> 11[3] via P2P/IPC/read
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 04/0 : 2[2] -> 3[3] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 01/0 : 10[2] -> 11[3] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 00/0 : 12[4] -> 13[5] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 02/0 : 10[2] -> 11[3] via P2P/IPC/read
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Channel 07/0 : 1[1] -> 2[2] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 01/0 : 12[4] -> 13[5] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 05/0 : 2[2] -> 3[3] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 03/0 : 10[2] -> 11[3] via P2P/IPC/read
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Channel 00/0 : 13[5] -> 14[6] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 01/0 : 0[0] -> 7[7] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 04/0 : 10[2] -> 11[3] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 02/0 : 12[4] -> 13[5] via P2P/IPC/read
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Channel 01/0 : 13[5] -> 14[6] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 03/0 : 12[4] -> 13[5] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 05/0 : 10[2] -> 11[3] via P2P/IPC/read
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Channel 02/0 : 13[5] -> 14[6] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 04/0 : 12[4] -> 13[5] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 06/0 : 10[2] -> 11[3] via P2P/IPC/read
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Channel 04/0 : 13[5] -> 14[6] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 05/0 : 12[4] -> 13[5] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 07/0 : 10[2] -> 11[3] via P2P/IPC/read
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 07/0 : 2[2] -> 3[3] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 03/0 : 0[0] -> 7[7] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 01/0 : 2[2] -> 10[2] [receive] via NET/AWS Libfabric/1/GDRDMA
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Channel 05/0 : 13[5] -> 14[6] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 05/0 : 2[2] -> 10[2] [receive] via NET/AWS Libfabric/1/GDRDMA
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 06/0 : 12[4] -> 13[5] via P2P/IPC/read
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 01/0 : 10[2] -> 2[2] [send] via NET/AWS Libfabric/1/GDRDMA
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Channel 05/0 : 10[2] -> 2[2] [send] via NET/AWS Libfabric/1/GDRDMA
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 00/0 : 6[6] -> 7[7] via P2P/IPC/read
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Channel 00/0 : 9[1] -> 8[0] via P2P/IPC/read
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Channel 06/0 : 13[5] -> 14[6] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 07/0 : 12[4] -> 13[5] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/IPC/read
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[4] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 05/0 : 0[0] -> 7[7] via P2P/IPC/read
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/IPC/read
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 01/0 : 6[6] -> 7[7] via P2P/IPC/read
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Channel 02/0 : 13[5] -> 12[4] via P2P/IPC/read
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 02/0 : 6[6] -> 7[7] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 02/0 : 4[4] -> 5[5] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 02/0 : 4[4] -> 12[4] [receive] via NET/AWS Libfabric/2/GDRDMA
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 06/0 : 4[4] -> 12[4] [receive] via NET/AWS Libfabric/2/GDRDMA
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Channel 01/0 : 15[7] -> 8[0] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 02/0 : 12[4] -> 4[4] [send] via NET/AWS Libfabric/2/GDRDMA
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Channel 06/0 : 13[5] -> 12[4] via P2P/IPC/read
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Channel 03/0 : 3[3] -> 4[4] via P2P/IPC/read
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[6] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 06/0 : 12[4] -> 4[4] [send] via NET/AWS Libfabric/2/GDRDMA
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 07/0 : 0[0] -> 7[7] via P2P/IPC/read
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 03/0 : 6[6] -> 7[7] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 03/0 : 4[4] -> 5[5] via P2P/IPC/read
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Channel 02/0 : 15[7] -> 8[0] via P2P/IPC/read
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Channel 03/0 : 15[7] -> 8[0] via P2P/IPC/read
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[6] via P2P/IPC/read
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Channel 05/0 : 15[7] -> 8[0] via P2P/IPC/read
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 04/0 : 6[6] -> 7[7] via P2P/IPC/read
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Channel 04/0 : 3[3] -> 4[4] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 04/0 : 4[4] -> 5[5] via P2P/IPC/read
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Channel 06/0 : 15[7] -> 8[0] via P2P/IPC/read
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Channel 07/0 : 15[7] -> 8[0] via P2P/IPC/read
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Channel 02/0 : 5[5] -> 6[6] via P2P/IPC/read
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 05/0 : 6[6] -> 7[7] via P2P/IPC/read
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Channel 05/0 : 3[3] -> 4[4] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 05/0 : 4[4] -> 5[5] via P2P/IPC/read
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Channel 04/0 : 5[5] -> 6[6] via P2P/IPC/read
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/IPC/read
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Channel 04/0 : 9[1] -> 8[0] via P2P/IPC/read
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 06/0 : 6[6] -> 7[7] via P2P/IPC/read
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 03/0 : 6[6] -> 14[6] [receive] via NET/AWS Libfabric/3/GDRDMA
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 07/0 : 6[6] -> 14[6] [receive] via NET/AWS Libfabric/3/GDRDMA
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 06/0 : 4[4] -> 5[5] via P2P/IPC/read
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Channel 07/0 : 3[3] -> 4[4] via P2P/IPC/read
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Channel 05/0 : 5[5] -> 6[6] via P2P/IPC/read
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 03/0 : 14[6] -> 6[6] [send] via NET/AWS Libfabric/3/GDRDMA
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Channel 07/0 : 14[6] -> 6[6] [send] via NET/AWS Libfabric/3/GDRDMA
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 07/0 : 4[4] -> 5[5] via P2P/IPC/read
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 00/0 : 0[0] -> 8[0] [receive] via NET/AWS Libfabric/0/GDRDMA
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 04/0 : 0[0] -> 8[0] [receive] via NET/AWS Libfabric/0/GDRDMA
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 00/0 : 8[0] -> 0[0] [send] via NET/AWS Libfabric/0/GDRDMA
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 07/0 : 6[6] -> 7[7] via P2P/IPC/read
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Channel 04/0 : 8[0] -> 0[0] [send] via NET/AWS Libfabric/0/GDRDMA
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Channel 06/0 : 5[5] -> 6[6] via P2P/IPC/read
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Channel 01/0 : 11[3] -> 10[2] via P2P/IPC/read
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Channel 05/0 : 11[3] -> 10[2] via P2P/IPC/read
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Channel 02/0 : 5[5] -> 4[4] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 02/0 : 12[4] -> 4[4] [receive] via NET/AWS Libfabric/2/GDRDMA
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 06/0 : 12[4] -> 4[4] [receive] via NET/AWS Libfabric/2/GDRDMA
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Channel 06/0 : 5[5] -> 4[4] via P2P/IPC/read
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 03/0 : 14[6] -> 6[6] [receive] via NET/AWS Libfabric/3/GDRDMA
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 02/0 : 4[4] -> 12[4] [send] via NET/AWS Libfabric/2/GDRDMA
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 07/0 : 14[6] -> 6[6] [receive] via NET/AWS Libfabric/3/GDRDMA
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 03/0 : 6[6] -> 14[6] [send] via NET/AWS Libfabric/3/GDRDMA
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 06/0 : 4[4] -> 12[4] [send] via NET/AWS Libfabric/2/GDRDMA
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Channel 07/0 : 6[6] -> 14[6] [send] via NET/AWS Libfabric/3/GDRDMA
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 01/0 : 4[4] -> 3[3] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 03/0 : 4[4] -> 3[3] via P2P/IPC/read
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 05/0 : 4[4] -> 3[3] via P2P/IPC/read
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Channel 07/0 : 4[4] -> 3[3] via P2P/IPC/read
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 01/0 : 10[2] -> 2[2] [receive] via NET/AWS Libfabric/1/GDRDMA
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 05/0 : 10[2] -> 2[2] [receive] via NET/AWS Libfabric/1/GDRDMA
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 01/0 : 2[2] -> 10[2] [send] via NET/AWS Libfabric/1/GDRDMA
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Channel 05/0 : 2[2] -> 10[2] [send] via NET/AWS Libfabric/1/GDRDMA
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 01/0 : 12[4] -> 11[3] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 03/0 : 12[4] -> 11[3] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 05/0 : 12[4] -> 11[3] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Channel 07/0 : 12[4] -> 11[3] via P2P/IPC/read
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Channel 01/0 : 7[7] -> 0[0] via P2P/IPC/read
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO Connected all trees
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO NCCL_PROTO set by environment to simple
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Channel 02/0 : 7[7] -> 0[0] via P2P/IPC/read
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Channel 03/0 : 7[7] -> 0[0] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 00/0 : 8[0] -> 0[0] [receive] via NET/AWS Libfabric/0/GDRDMA
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 04/0 : 8[0] -> 0[0] [receive] via NET/AWS Libfabric/0/GDRDMA
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 00/0 : 0[0] -> 8[0] [send] via NET/AWS Libfabric/0/GDRDMA
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Channel 04/0 : 0[0] -> 8[0] [send] via NET/AWS Libfabric/0/GDRDMA
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Channel 05/0 : 7[7] -> 0[0] via P2P/IPC/read
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO Connected all trees
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO NCCL_PROTO set by environment to simple
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO Connected all trees
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO NCCL_PROTO set by environment to simple
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Channel 06/0 : 7[7] -> 0[0] via P2P/IPC/read
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Channel 07/0 : 7[7] -> 0[0] via P2P/IPC/read
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO Connected all trees
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO NCCL_PROTO set by environment to simple
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Channel 03/0 : 7[7] -> 6[6] via P2P/IPC/read
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO Connected all trees
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO NCCL_PROTO set by environment to simple
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Channel 03/0 : 15[7] -> 14[6] via P2P/IPC/read
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Channel 07/0 : 7[7] -> 6[6] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO Connected all trees
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO NCCL_PROTO set by environment to simple
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO Connected all trees
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO NCCL_PROTO set by environment to simple
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO Connected all trees
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO NCCL_PROTO set by environment to simple
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Channel 07/0 : 15[7] -> 14[6] via P2P/IPC/read
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO Connected all trees
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO NCCL_PROTO set by environment to simple
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO Connected all trees
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO NCCL_PROTO set by environment to simple
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO Connected all trees
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO NCCL_PROTO set by environment to simple
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO Connected all trees
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO NCCL_PROTO set by environment to simple
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO Connected all trees
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO NCCL_PROTO set by environment to simple
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO Connected all trees
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO NCCL_PROTO set by environment to simple
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO Connected all trees
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO NCCL_PROTO set by environment to simple
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO Connected all trees
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO NCCL_PROTO set by environment to simple
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
 6: compute-gpu-st-distributed-ml-1:77190:77593 [6] NCCL INFO comm 0x558fa21e42d0 rank 6 nranks 16 cudaDev 6 nvmlDev 6 busId a01c0 commId 0x94343f5a50e0fc8e - Init COMPLETE
 7: compute-gpu-st-distributed-ml-1:77191:77594 [7] NCCL INFO comm 0x55775a100140 rank 7 nranks 16 cudaDev 7 nvmlDev 7 busId a01d0 commId 0x94343f5a50e0fc8e - Init COMPLETE
 1: compute-gpu-st-distributed-ml-1:77185:77598 [1] NCCL INFO comm 0x560bd1fa4640 rank 1 nranks 16 cudaDev 1 nvmlDev 1 busId 101d0 commId 0x94343f5a50e0fc8e - Init COMPLETE
 0: compute-gpu-st-distributed-ml-1:77184:77589 [0] NCCL INFO comm 0x5559cbb825c0 rank 0 nranks 16 cudaDev 0 nvmlDev 0 busId 101c0 commId 0x94343f5a50e0fc8e - Init COMPLETE
 0: #
 0: #                                                              out-of-place                       in-place          
 0: #       size         count      type   redop    root     time   algbw   busbw #wrong     time   algbw   busbw #wrong
 0: #        (B)    (elements)                               (us)  (GB/s)  (GB/s)            (us)  (GB/s)  (GB/s)       
 5: compute-gpu-st-distributed-ml-1:77189:77592 [5] NCCL INFO comm 0x55ff5096fdf0 rank 5 nranks 16 cudaDev 5 nvmlDev 5 busId 901d0 commId 0x94343f5a50e0fc8e - Init COMPLETE
 4: compute-gpu-st-distributed-ml-1:77188:77595 [4] NCCL INFO comm 0x5626f5bda160 rank 4 nranks 16 cudaDev 4 nvmlDev 4 busId 901c0 commId 0x94343f5a50e0fc8e - Init COMPLETE
 3: compute-gpu-st-distributed-ml-1:77187:77597 [3] NCCL INFO comm 0x562ff6427610 rank 3 nranks 16 cudaDev 3 nvmlDev 3 busId 201d0 commId 0x94343f5a50e0fc8e - Init COMPLETE
 2: compute-gpu-st-distributed-ml-1:77186:77596 [2] NCCL INFO comm 0x5613e001b5c0 rank 2 nranks 16 cudaDev 2 nvmlDev 2 busId 201c0 commId 0x94343f5a50e0fc8e - Init COMPLETE
13: compute-gpu-st-distributed-ml-2:60029:60442 [5] NCCL INFO comm 0x55b255c27e20 rank 13 nranks 16 cudaDev 5 nvmlDev 5 busId 901d0 commId 0x94343f5a50e0fc8e - Init COMPLETE
 9: compute-gpu-st-distributed-ml-2:60025:60439 [1] NCCL INFO comm 0x5599acfaccd0 rank 9 nranks 16 cudaDev 1 nvmlDev 1 busId 101d0 commId 0x94343f5a50e0fc8e - Init COMPLETE
10: compute-gpu-st-distributed-ml-2:60026:60436 [2] NCCL INFO comm 0x5650a588b3d0 rank 10 nranks 16 cudaDev 2 nvmlDev 2 busId 201c0 commId 0x94343f5a50e0fc8e - Init COMPLETE
14: compute-gpu-st-distributed-ml-2:60030:60438 [6] NCCL INFO comm 0x5637ea53e2f0 rank 14 nranks 16 cudaDev 6 nvmlDev 6 busId a01c0 commId 0x94343f5a50e0fc8e - Init COMPLETE
11: compute-gpu-st-distributed-ml-2:60027:60437 [3] NCCL INFO comm 0x55670668f200 rank 11 nranks 16 cudaDev 3 nvmlDev 3 busId 201d0 commId 0x94343f5a50e0fc8e - Init COMPLETE
15: compute-gpu-st-distributed-ml-2:60031:60440 [7] NCCL INFO comm 0x564af14721d0 rank 15 nranks 16 cudaDev 7 nvmlDev 7 busId a01d0 commId 0x94343f5a50e0fc8e - Init COMPLETE
12: compute-gpu-st-distributed-ml-2:60028:60441 [4] NCCL INFO comm 0x5605a8b16440 rank 12 nranks 16 cudaDev 4 nvmlDev 4 busId 901c0 commId 0x94343f5a50e0fc8e - Init COMPLETE
 8: compute-gpu-st-distributed-ml-2:60024:60435 [0] NCCL INFO comm 0x55a489a7b1a0 rank 8 nranks 16 cudaDev 0 nvmlDev 0 busId 101c0 commId 0x94343f5a50e0fc8e - Init COMPLETE
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 00/1 : 0[0] -> 1[1] via P2P/IPC/read
12: compute-gpu-st-distributed-ml-2:60028:60467 [4] NCCL INFO Channel 04/1 : 0[0] -> 12[4] [receive] via NET/AWS Libfabric/2/GDRDMA/Shared
10: compute-gpu-st-distributed-ml-2:60026:60470 [2] NCCL INFO Channel 04/1 : 0[0] -> 10[2] [receive] via NET/AWS Libfabric/1/GDRDMA/Shared
12: compute-gpu-st-distributed-ml-2:60028:60467 [4] NCCL INFO Channel 05/1 : 0[0] -> 12[4] [receive] via NET/AWS Libfabric/2/GDRDMA/Shared
 8: compute-gpu-st-distributed-ml-2:60024:60468 [0] NCCL INFO Channel 04/1 : 0[0] -> 8[0] [receive] via NET/AWS Libfabric/0/GDRDMA/Shared
10: compute-gpu-st-distributed-ml-2:60026:60470 [2] NCCL INFO Channel 05/1 : 0[0] -> 10[2] [receive] via NET/AWS Libfabric/1/GDRDMA/Shared
 8: compute-gpu-st-distributed-ml-2:60024:60468 [0] NCCL INFO Channel 05/1 : 0[0] -> 8[0] [receive] via NET/AWS Libfabric/0/GDRDMA/Shared
14: compute-gpu-st-distributed-ml-2:60030:60469 [6] NCCL INFO Channel 04/1 : 0[0] -> 14[6] [receive] via NET/AWS Libfabric/3/GDRDMA/Shared
14: compute-gpu-st-distributed-ml-2:60030:60469 [6] NCCL INFO Channel 05/1 : 0[0] -> 14[6] [receive] via NET/AWS Libfabric/3/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 01/1 : 0[0] -> 1[1] via P2P/IPC/read
13: compute-gpu-st-distributed-ml-2:60029:60471 [5] NCCL INFO Channel 04/1 : 0[0] -> 13[5] [receive] via NET/AWS Libfabric/2/GDRDMA/Shared
 9: compute-gpu-st-distributed-ml-2:60025:60472 [1] NCCL INFO Channel 04/1 : 0[0] -> 9[1] [receive] via NET/AWS Libfabric/0/GDRDMA/Shared
11: compute-gpu-st-distributed-ml-2:60027:60474 [3] NCCL INFO Channel 04/1 : 0[0] -> 11[3] [receive] via NET/AWS Libfabric/1/GDRDMA/Shared
13: compute-gpu-st-distributed-ml-2:60029:60471 [5] NCCL INFO Channel 05/1 : 0[0] -> 13[5] [receive] via NET/AWS Libfabric/2/GDRDMA/Shared
 9: compute-gpu-st-distributed-ml-2:60025:60472 [1] NCCL INFO Channel 05/1 : 0[0] -> 9[1] [receive] via NET/AWS Libfabric/0/GDRDMA/Shared
11: compute-gpu-st-distributed-ml-2:60027:60474 [3] NCCL INFO Channel 05/1 : 0[0] -> 11[3] [receive] via NET/AWS Libfabric/1/GDRDMA/Shared
15: compute-gpu-st-distributed-ml-2:60031:60473 [7] NCCL INFO Channel 04/1 : 0[0] -> 15[7] [receive] via NET/AWS Libfabric/3/GDRDMA/Shared
15: compute-gpu-st-distributed-ml-2:60031:60473 [7] NCCL INFO Channel 05/1 : 0[0] -> 15[7] [receive] via NET/AWS Libfabric/3/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 00/1 : 0[0] -> 2[2] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 01/1 : 0[0] -> 2[2] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 00/1 : 0[0] -> 3[3] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 01/1 : 0[0] -> 3[3] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 00/1 : 0[0] -> 4[4] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 01/1 : 0[0] -> 4[4] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 00/1 : 0[0] -> 5[5] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 01/1 : 0[0] -> 5[5] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 00/1 : 0[0] -> 6[6] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 01/1 : 0[0] -> 6[6] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 00/1 : 0[0] -> 7[7] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 01/1 : 0[0] -> 7[7] via P2P/IPC/read
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 04/1 : 0[0] -> 8[0] [send] via NET/AWS Libfabric/0/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 05/1 : 0[0] -> 8[0] [send] via NET/AWS Libfabric/0/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 04/1 : 0[0] -> 9[1] [send] via NET/AWS Libfabric/0/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 05/1 : 0[0] -> 9[1] [send] via NET/AWS Libfabric/0/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 04/1 : 0[0] -> 10[2] [send] via NET/AWS Libfabric/1(2)/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 05/1 : 0[0] -> 10[2] [send] via NET/AWS Libfabric/1(2)/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 04/1 : 0[0] -> 11[3] [send] via NET/AWS Libfabric/1(2)/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 05/1 : 0[0] -> 11[3] [send] via NET/AWS Libfabric/1(2)/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 04/1 : 0[0] -> 12[4] [send] via NET/AWS Libfabric/2(4)/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 05/1 : 0[0] -> 12[4] [send] via NET/AWS Libfabric/2(4)/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 04/1 : 0[0] -> 13[5] [send] via NET/AWS Libfabric/2(4)/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 05/1 : 0[0] -> 13[5] [send] via NET/AWS Libfabric/2(4)/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 04/1 : 0[0] -> 14[6] [send] via NET/AWS Libfabric/3(6)/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 05/1 : 0[0] -> 14[6] [send] via NET/AWS Libfabric/3(6)/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 04/1 : 0[0] -> 15[7] [send] via NET/AWS Libfabric/3(6)/GDRDMA/Shared
 0: compute-gpu-st-distributed-ml-1:77184:77623 [0] NCCL INFO Channel 05/1 : 0[0] -> 15[7] [send] via NET/AWS Libfabric/3(6)/GDRDMA/Shared
 0:            0             0     float    none       0     0.14    0.00    0.00      0     0.14    0.00    0.00      0
 0:            0             0     float    none       0     0.14    0.00    0.00      0     0.14    0.00    0.00      0
 0:            0             0     float    none       0     0.13    0.00    0.00      0     0.14    0.00    0.00      0
 0:           64             1     float    none       0    89.27    0.00    0.00      0    89.52    0.00    0.00      0
 0:          128             2     float    none       0    89.18    0.00    0.00      0    176.6    0.00    0.00      0
 0:          256             4     float    none       0    88.43    0.00    0.00      0    89.37    0.00    0.00      0
 0:          512             8     float    none       0    87.55    0.01    0.01      0    89.63    0.01    0.01      0
 0:         1024            16     float    none       0    88.90    0.01    0.01      0    89.26    0.01    0.01      0
 0:         2048            32     float    none       0    88.81    0.02    0.02      0    86.93    0.02    0.02      0
 0:         4096            64     float    none       0    86.57    0.05    0.04      0    88.61    0.05    0.04      0
 0:         8192           128     float    none       0    85.93    0.10    0.09      0    85.73    0.10    0.09      0
 0:        16384           256     float    none       0    102.0    0.16    0.15      0    91.98    0.18    0.17      0
 0:        32768           512     float    none       0    93.94    0.35    0.33      0    94.18    0.35    0.33      0
 0:        65536          1024     float    none       0    92.05    0.71    0.67      0    137.0    0.48    0.45      0
 0:       131072          2048     float    none       0    85.07    1.54    1.44      0    110.4    1.19    1.11      0
 0:       262144          4096     float    none       0    103.1    2.54    2.38      0    119.6    2.19    2.06      0
 0:       524288          8192     float    none       0    114.3    4.59    4.30      0    115.2    4.55    4.27      0
 0:      1048576         16384     float    none       0    124.8    8.40    7.87      0    124.1    8.45    7.92      0
 0:      2097152         32768     float    none       0    166.4   12.60   11.82      0    166.5   12.59   11.81      0
 0:      4194304         65536     float    none       0    223.6   18.76   17.59      0    216.3   19.39   18.18      0
 0:      8388608        131072     float    none       0    363.9   23.05   21.61      0    370.9   22.62   21.20      0
 0:     16777216        262144     float    none       0    521.0   32.20   30.19      0    533.8   31.43   29.46      0
 0:     33554432        524288     float    none       0    672.7   49.88   46.76      0    665.9   50.39   47.24      0
 0:     67108864       1048576     float    none       0   1058.7   63.39   59.43      0   1058.0   63.43   59.46      0
 0:    134217728       2097152     float    none       0   1808.8   74.20   69.57      0   1823.4   73.61   69.01      0
 0:    268435456       4194304     float    none       0   3335.1   80.49   75.46      0   3361.8   79.85   74.86      0
 0:    536870912       8388608     float    none       0   6422.1   83.60   78.37      0   6412.3   83.73   78.49      0
 0:   1073741824      16777216     float    none       0    12734   84.32   79.05      0    12543   85.61   80.26      0
 0:   2147483648      33554432     float    none       0    24982   85.96   80.59      0    24829   86.49   81.09      0
13: compute-gpu-st-distributed-ml-2:60029:60029 [5] NCCL INFO comm 0x55b255c27e20 rank 13 nranks 16 cudaDev 5 busId 901d0 - Destroy COMPLETE
 1: compute-gpu-st-distributed-ml-1:77185:77185 [1] NCCL INFO comm 0x560bd1fa4640 rank 1 nranks 16 cudaDev 1 busId 101d0 - Destroy COMPLETE
 5: compute-gpu-st-distributed-ml-1:77189:77189 [5] NCCL INFO comm 0x55ff5096fdf0 rank 5 nranks 16 cudaDev 5 busId 901d0 - Destroy COMPLETE
15: compute-gpu-st-distributed-ml-2:60031:60031 [7] NCCL INFO comm 0x564af14721d0 rank 15 nranks 16 cudaDev 7 busId a01d0 - Destroy COMPLETE
11: compute-gpu-st-distributed-ml-2:60027:60027 [3] NCCL INFO comm 0x55670668f200 rank 11 nranks 16 cudaDev 3 busId 201d0 - Destroy COMPLETE
 3: compute-gpu-st-distributed-ml-1:77187:77187 [3] NCCL INFO comm 0x562ff6427610 rank 3 nranks 16 cudaDev 3 busId 201d0 - Destroy COMPLETE
 7: compute-gpu-st-distributed-ml-1:77191:77191 [7] NCCL INFO comm 0x55775a100140 rank 7 nranks 16 cudaDev 7 busId a01d0 - Destroy COMPLETE
 9: compute-gpu-st-distributed-ml-2:60025:60025 [1] NCCL INFO comm 0x5599acfaccd0 rank 9 nranks 16 cudaDev 1 busId 101d0 - Destroy COMPLETE
 2: compute-gpu-st-distributed-ml-1:77186:77186 [2] NCCL INFO comm 0x5613e001b5c0 rank 2 nranks 16 cudaDev 2 busId 201c0 - Destroy COMPLETE
 6: compute-gpu-st-distributed-ml-1:77190:77190 [6] NCCL INFO comm 0x558fa21e42d0 rank 6 nranks 16 cudaDev 6 busId a01c0 - Destroy COMPLETE
14: compute-gpu-st-distributed-ml-2:60030:60030 [6] NCCL INFO comm 0x5637ea53e2f0 rank 14 nranks 16 cudaDev 6 busId a01c0 - Destroy COMPLETE
10: compute-gpu-st-distributed-ml-2:60026:60026 [2] NCCL INFO comm 0x5650a588b3d0 rank 10 nranks 16 cudaDev 2 busId 201c0 - Destroy COMPLETE
 8: compute-gpu-st-distributed-ml-2:60024:60024 [0] NCCL INFO comm 0x55a489a7b1a0 rank 8 nranks 16 cudaDev 0 busId 101c0 - Destroy COMPLETE
12: compute-gpu-st-distributed-ml-2:60028:60028 [4] NCCL INFO comm 0x5605a8b16440 rank 12 nranks 16 cudaDev 4 busId 901c0 - Destroy COMPLETE
 4: compute-gpu-st-distributed-ml-1:77188:77188 [4] NCCL INFO comm 0x5626f5bda160 rank 4 nranks 16 cudaDev 4 busId 901c0 - Destroy COMPLETE
 0: compute-gpu-st-distributed-ml-1:77184:77184 [0] NCCL INFO comm 0x5559cbb825c0 rank 0 nranks 16 cudaDev 0 busId 101c0 - Destroy COMPLETE
 0: # Out of bounds values : 0 OK
 0: # Avg bus bandwidth    : 20.2635 
 0: #
 0: 
